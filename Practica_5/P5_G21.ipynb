{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5 Visión por Computador\n",
    "## Autores:\n",
    "- Héctor Wood Santana\n",
    "- Alejandro Viera Ruiz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea.\n",
    "Tras mostrar opciones para la detección y extracción de información de caras humanas con deepface, la tarea a entregar consiste en proponer un escenario de aplicación y desarrollar un prototipo de temática libreque provoque reacciones a partir de la información extraida del rostro. Los detectores proporcionan información del rostro, y de sus elementos faciales. Ideas inmediatas pueden ser filtros, aunque no hay limitaciones en este sentido. La entrega debe venir acompañada de un gif animado o vídeo de un máximo de 30 segundos con momentos seleccionados de la propuesta. Se utilizará para una posterior votación y elección de las mejores entre el grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "# My face detectors interface\n",
    "import FaceDetectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n",
      "Dimensiones de la imagen de gafas: (433, 577, 4)\n",
      "Dimensiones de la imagen del sombrero: (500, 500, 4)\n"
     ]
    }
   ],
   "source": [
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "# Face detectors interface\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "# Fonts\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "# Face detection and eye model setup\n",
    "imodoF = 2  # DNN \n",
    "imodoE = 1  # DLIB68\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "# Modos\n",
    "mode = 0\n",
    "\n",
    "# Cargamos las imagenes de las gafas\n",
    "gafas = cv2.imread('gafas1sinfondo.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Imprimir información sobre la imagen cargada\n",
    "if gafas is not None:\n",
    "    print(\"Dimensiones de la imagen de gafas:\", gafas.shape)\n",
    "else:\n",
    "    print(\"Error: La imagen de las gafas no se pudo cargar. Verifica la ruta o el archivo.\")\n",
    "\n",
    "# Verifica si las gafas tienen canal alfa; si no, añade uno manualmente\n",
    "if gafas.shape[2] == 3:  # Si no tiene canal alfa\n",
    "    gafas = cv2.cvtColor(gafas, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "\n",
    "# Cargamos las imagenes del sombrero\n",
    "sombrero = cv2.imread('sombrerosinfondo.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Imprimir información sobre la imagen cargada\n",
    "if sombrero is not None:\n",
    "    print(\"Dimensiones de la imagen del sombrero:\", sombrero.shape)\n",
    "else:\n",
    "    print(\"Error: La imagen del sombrero no se pudo cargar. Verifica la ruta o el archivo.\")\n",
    "\n",
    "# Verifica si las gafas tienen canal alfa; si no, añade uno manualmente\n",
    "if sombrero.shape[2] == 3:  # Si no tiene canal alfa\n",
    "    sombrero = cv2.cvtColor(sombrero, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # For HS normalization\n",
    "        B, G, R = cv2.split(frame)\n",
    "\n",
    "        # Search face with a specific setup for face and eye detection\n",
    "        values = FDet.SingleFaceEyesDetection(frame, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "        if values is not None:\n",
    "            face, eyes, shape = values\n",
    "\n",
    "            #draws face container\n",
    "            [x, y , w, h] = face\n",
    "            if x > -1:\n",
    "                \n",
    "\n",
    "                # draws eyes and mask if available\n",
    "                [lex, ley, rex, rey] = eyes\n",
    "                if lex > -1 and rex > -1:\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    #Cambiamos de modo\n",
    "                    if mode == 0:\n",
    "                        # Show detected facial elements (Dibuja puntos de contorno de la cara)\n",
    "                        # Bounding Box de la cara\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                        if imodoF > 0:\n",
    "                            for (x, y) in shape:\n",
    "                                cv2.circle(frame, (x, y), 2, (255, 255, 255), -1)\n",
    "\n",
    "                        #Puntos del centro de los ojos\n",
    "                        cv2.circle(frame, ((int)(lex), (int)(ley)), 4, (0, 0, 255), -1)\n",
    "                        cv2.circle(frame, ((int)(rex), (int)(rey)), 4, (0, 255, 0), -1)\n",
    "                    elif mode == 1:\n",
    "                        # Calculamos la distancia entre los ojos\n",
    "                        distancia_ojos = int(np.sqrt((rex - lex) ** 2 + (rey - ley) ** 2))\n",
    "                        # Redimensionamos las gafas\n",
    "                        gafas_resized = cv2.resize(gafas, (int(distancia_ojos * 2.5), int(distancia_ojos * 1.2)))                    \n",
    "                        # Calculo del las posiciones de la gafa\n",
    "                        y_offset = int((ley + rey) / 2 - gafas_resized.shape[0] / 2)\n",
    "                        x_offset = int((lex + rex) / 2 - gafas_resized.shape[1] / 2)\n",
    "                        \n",
    "                        # Cálculo de transparencia y canales RGB\n",
    "                        alpha = gafas_resized[:, :, 3] / 255.0  # Canal alfa (normalizado entre 0 y 1)\n",
    "                        gafas_rgb = gafas_resized[:, :, :3]  # Los colores RGB (sin el canal alfa)\n",
    "\n",
    "                        # Calcular los índices de la región del frame donde se va a superponer la imagen\n",
    "                        y_start = max(y_offset, 0)\n",
    "                        y_end = min(y_offset + gafas_resized.shape[0], frame.shape[0])\n",
    "                        x_start = max(x_offset, 0)\n",
    "                        x_end = min(x_offset + gafas_resized.shape[1], frame.shape[1])\n",
    "\n",
    "                        # Extraer el fragmento del frame que será modificado\n",
    "                        frame_region = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                        # Calcular el área que debe ser modificada (donde el alfa es mayor que 0)\n",
    "                        alpha_mask = alpha[y_start - y_offset:y_end - y_offset, x_start - x_offset:x_end - x_offset]\n",
    "                        frame[y_start:y_end, x_start:x_end] = (1 - alpha_mask[..., None]) * frame_region + alpha_mask[..., None] * gafas_rgb[y_start - y_offset:y_end - y_offset, x_start - x_offset:x_end - x_offset]\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    elif mode == 2:\n",
    "                        # Redimensionar el sombrero en función del ancho del bounding box de la cara\n",
    "                        ancho_sombrero = int(w * 2)\n",
    "                        alto_sombrero = int(ancho_sombrero * sombrero.shape[0] / sombrero.shape[1]) \n",
    "                        sombrero_resized = cv2.resize(sombrero, (ancho_sombrero, alto_sombrero))\n",
    "                        \n",
    "                        # Calcular la posición para colocar el sombrero encima de la cara\n",
    "                        x_offset = int(x + w / 2) - int(ancho_sombrero / 2)\n",
    "                        y_offset = int(((y + (h/2)) - alto_sombrero))\n",
    "                        \n",
    "                        # Cálculo de transparencia y canales RGB\n",
    "                        alpha = sombrero_resized[:, :, 3] / 255.0  # Canal alfa (normalizado entre 0 y 1)\n",
    "                        sombrero_rgb = sombrero_resized[:, :, :3]  # Los colores RGB (sin el canal alfa)\n",
    "\n",
    "                        # Calcular los índices de la región del frame donde se va a superponer la imagen\n",
    "                        y_start = max(y_offset, 0)\n",
    "                        y_end = min(y_offset + sombrero_resized.shape[0], frame.shape[0])\n",
    "                        x_start = max(x_offset, 0)\n",
    "                        x_end = min(x_offset + sombrero_resized.shape[1], frame.shape[1])\n",
    "\n",
    "                        # Extraer el fragmento del frame que será modificado\n",
    "                        frame_region = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                        # Calcular el área que debe ser modificada (donde el alfa es mayor que 0)\n",
    "                        alpha_mask = alpha[y_start - y_offset:y_end - y_offset, x_start - x_offset:x_end - x_offset]\n",
    "                        frame[y_start:y_end, x_start:x_end] = (1 - alpha_mask[..., None]) * frame_region + alpha_mask[..., None] * sombrero_rgb[y_start - y_offset:y_end - y_offset, x_start - x_offset:x_end - x_offset]\n",
    "                    \n",
    "                    elif mode == 3:\n",
    "                        # Calculamos la distancia entre los ojos\n",
    "                        distancia_ojos = int(np.sqrt((rex - lex) ** 2 + (rey - ley) ** 2))\n",
    "                        # Redimensionamos las gafas\n",
    "                        gafas_resized = cv2.resize(gafas, (int(distancia_ojos * 2.5), int(distancia_ojos * 1.2)))\n",
    "                        # Redimensionar el sombrero en función del ancho del bounding box de la cara\n",
    "                        ancho_sombrero = int(w * 2)\n",
    "                        alto_sombrero = int(ancho_sombrero * sombrero.shape[0] / sombrero.shape[1]) \n",
    "                        sombrero_resized = cv2.resize(sombrero, (ancho_sombrero, alto_sombrero))                    \n",
    "                        # Calculo del las posiciones de la gafa\n",
    "                        y_offset_gafa = int((ley + rey) / 2 - gafas_resized.shape[0] / 2)\n",
    "                        x_offset_gafa = int((lex + rex) / 2 - gafas_resized.shape[1] / 2)\n",
    "                        # Calcular la posición para colocar el sombrero encima de la cara\n",
    "                        x_offset_sombrero = int(x + w / 2) - int(ancho_sombrero / 2)\n",
    "                        y_offset_sombrero = int(((y + (h/2)) - alto_sombrero))\n",
    "                        # Superposición de las gafas\n",
    "                        # Cálculo de transparencia y canales RGB\n",
    "                        alpha = gafas_resized[:, :, 3] / 255.0  # Canal alfa (normalizado entre 0 y 1)\n",
    "                        gafas_rgb = gafas_resized[:, :, :3]  # Los colores RGB (sin el canal alfa)\n",
    "\n",
    "                        # Calcular los índices de la región del frame donde se va a superponer la imagen\n",
    "                        y_start = max(y_offset_gafa, 0)\n",
    "                        y_end = min(y_offset_gafa + gafas_resized.shape[0], frame.shape[0])\n",
    "                        x_start = max(x_offset_gafa, 0)\n",
    "                        x_end = min(x_offset_gafa + gafas_resized.shape[1], frame.shape[1])\n",
    "\n",
    "                        # Extraer el fragmento del frame que será modificado\n",
    "                        frame_region = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                        # Calcular el área que debe ser modificada (donde el alfa es mayor que 0)\n",
    "                        alpha_mask = alpha[y_start - y_offset_gafa:y_end - y_offset_gafa, x_start - x_offset_gafa:x_end - x_offset_gafa]\n",
    "                        frame[y_start:y_end, x_start:x_end] = (1 - alpha_mask[..., None]) * frame_region + alpha_mask[..., None] * gafas_rgb[y_start - y_offset_gafa:y_end - y_offset_gafa, x_start - x_offset_gafa:x_end - x_offset_gafa]\n",
    "                        # Superponer el sombrero en el frame usando transparencia (canal alfa)\n",
    "                        # Cálculo de transparencia y canales RGB\n",
    "                        alpha = sombrero_resized[:, :, 3] / 255.0  # Canal alfa (normalizado entre 0 y 1)\n",
    "                        sombrero_rgb = sombrero_resized[:, :, :3]  # Los colores RGB (sin el canal alfa)\n",
    "\n",
    "                        # Calcular los índices de la región del frame donde se va a superponer la imagen\n",
    "                        y_start = max(y_offset_sombrero, 0)\n",
    "                        y_end = min(y_offset_sombrero + sombrero_resized.shape[0], frame.shape[0])\n",
    "                        x_start = max(x_offset_sombrero, 0)\n",
    "                        x_end = min(x_offset_sombrero + sombrero_resized.shape[1], frame.shape[1])\n",
    "\n",
    "                        # Extraer el fragmento del frame que será modificado\n",
    "                        frame_region = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                        # Calcular el área que debe ser modificada (donde el alfa es mayor que 0)\n",
    "                        alpha_mask = alpha[y_start - y_offset_sombrero:y_end - y_offset_sombrero, x_start - x_offset_sombrero:x_end - x_offset_sombrero]\n",
    "                        frame[y_start:y_end, x_start:x_end] = (1 - alpha_mask[..., None]) * frame_region + alpha_mask[..., None] * sombrero_rgb[y_start - y_offset_sombrero:y_end - y_offset_sombrero, x_start - x_offset_sombrero:x_end - x_offset_sombrero]\n",
    "\n",
    "\n",
    "                    # Normalize and show\n",
    "                    # color channels\n",
    "                    normalizatorHS.normalize_gray_img(B, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Bnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(G, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Gnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(R, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Rnorm = normalizatorHS.normf_image\n",
    "                    NormBGR = cv2.merge((Bnorm, Gnorm, Rnorm))\n",
    "                    cv2.imshow(\"Normalized\", NormBGR)\n",
    "\n",
    "        # Show resulting image\n",
    "        cv2.imshow('Cam', frame)\n",
    "        \n",
    "        # Esc to finish\n",
    "        tec = cv2.waitKey(40)\n",
    "        if tec & tec == 27:  # Esc\n",
    "            break\n",
    "        elif tec & 0xFF == ord('0'):\n",
    "            mode = 0\n",
    "        elif tec & 0xFF == ord('1'):\n",
    "            mode = 1\n",
    "        elif tec & 0xFF == ord('2'):\n",
    "            mode = 2\n",
    "        elif tec & 0xFF == ord('3'):\n",
    "            mode = 3\n",
    "            \n",
    "\n",
    "# Close windoews and release camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
